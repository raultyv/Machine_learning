{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50be085d",
      "metadata": {
        "id": "50be085d"
      },
      "source": [
        "# Regularización L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5480689",
      "metadata": {
        "cellView": "form",
        "id": "e5480689",
        "outputId": "e0388ad2-a10b-4f48-8522-ba6021f3acdd",
        "colab": {
          "referenced_widgets": [
            "79099429ebb44ff389f5bd88aa32ca60",
            "cfcc32c045d346f88f991d1834686c5d"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79099429ebb44ff389f5bd88aa32ca60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatSlider(value=4.0, continuous_update=False, description='Rango ±k·σ', max=8.0, min=1.0, ste…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfcc32c045d346f88f991d1834686c5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Parámetros fijos de la Gaussiana\n",
        "MU = 0.0\n",
        "SIGMA = 1.0\n",
        "\n",
        "# Umbral fijo para definir \"colas\" dentro del rango visible: colas si |w-μ| >= T·σ\n",
        "T = 2.0  # cambia a 1.0 o 3.0 si prefieres\n",
        "\n",
        "def normal_pdf(x, mu=0.0, sigma=1.0):\n",
        "    return (1.0 / (np.sqrt(2*np.pi) * sigma)) * np.exp(-0.5 * ((x - mu)/sigma)**2)\n",
        "\n",
        "def normal_cdf(z):\n",
        "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
        "\n",
        "# Slider: rango del eje X (en múltiplos de σ)\n",
        "k_slider = widgets.FloatSlider(\n",
        "    value=4.0, min=1.0, max=8.0, step=0.5,\n",
        "    description=\"Rango ±k·σ\", continuous_update=False\n",
        ")\n",
        "\n",
        "# Checkbox: incluir o no la curva de costo w^2\n",
        "show_cost = widgets.Checkbox(value=True, description=\"Mostrar costo $w^2$\")\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def update(*_):\n",
        "    with out:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        k = float(k_slider.value)\n",
        "\n",
        "        # Eje X: μ ± kσ\n",
        "        x = np.linspace(MU - k*SIGMA, MU + k*SIGMA, 1200)\n",
        "        pdf = normal_pdf(x, MU, SIGMA)\n",
        "\n",
        "        # Umbrales de colas dentro del rango visible\n",
        "        left_thr = MU - T*SIGMA\n",
        "        right_thr = MU + T*SIGMA\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(x, pdf, label=r\"PDF $\\mathcal{N}(0,1)$\")\n",
        "\n",
        "        # Sombrear colas SOLO si k > T\n",
        "        if k > T:\n",
        "            plt.fill_between(x[x <= left_thr], pdf[x <= left_thr], alpha=0.25, label=f\"Cola izquierda (≤ -{T}σ)\")\n",
        "            plt.fill_between(x[x >= right_thr], pdf[x >= right_thr], alpha=0.25, label=f\"Cola derecha (≥ +{T}σ)\")\n",
        "            plt.axvline(left_thr, linestyle=\":\")\n",
        "            plt.axvline(right_thr, linestyle=\":\")\n",
        "\n",
        "            p_central = 2 * normal_cdf(T) - 1.0\n",
        "            p_tails = 1.0 - p_central\n",
        "            tails_msg = f\"P(|X-μ| > {T}σ) = {p_tails:.4f}\"\n",
        "        else:\n",
        "            tails_msg = f\"(k ≤ {T}) No hay espacio suficiente para mostrar colas definidas por ±{T}σ.\"\n",
        "\n",
        "        # Curva de costo opcional\n",
        "        if show_cost.value:\n",
        "            cost = x**2\n",
        "            cost_scaled = (cost / (np.max(cost) + 1e-12)) * np.max(pdf)\n",
        "            plt.plot(x, cost_scaled, linestyle=\"--\", label=r\"Costo $w^2$ (escalado)\")\n",
        "\n",
        "        plt.axvline(MU, linestyle=\":\", label=\"μ = 0\")\n",
        "        plt.title(f\"Gaussiana y colas (colas definidas por |w-μ| ≥ {T}σ)\")\n",
        "        plt.xlabel(\"w\")\n",
        "        plt.ylabel(\"PDF (y costo escalado si se activa)\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(tails_msg)\n",
        "\n",
        "k_slider.observe(update, names=\"value\")\n",
        "show_cost.observe(update, names=\"value\")\n",
        "\n",
        "display(widgets.HBox([k_slider, show_cost]), out)\n",
        "update()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9fbd71b",
      "metadata": {
        "id": "d9fbd71b"
      },
      "source": [
        "## 1. Modelo de regresión lineal\n",
        "Sea un modelo lineal con dos variables:\n",
        "\n",
        "$$\n",
        "\\hat{y} = w_1 x_1 + w_2 x_2\n",
        "$$\n",
        "\n",
        "La función de costo clásica de **Ordinary Least Squares (OLS)** es:\n",
        "\n",
        "$$\n",
        "J_{\\text{MSE}}(\\mathbf{w}) =\n",
        "\\frac{1}{n}\\sum_{i=1}^{n}\\left(\\hat{y}_{i} - y_{i}\\right)^2\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3dc863c",
      "metadata": {
        "id": "c3dc863c"
      },
      "source": [
        "## 2. Distancia de Minkowski\n",
        "\n",
        "La **distancia de Minkowski** es una familia de distancias que generaliza varias métricas conocidas, controladas por un parámetro $p$.\n",
        "\n",
        "Su fórmula es:\n",
        "\n",
        "$$\n",
        "d_p(\\mathbf{x}, \\mathbf{y})\n",
        "=\n",
        "\\left(\n",
        "\\sum_{i=1}^{n} |x_i - y_i|^p\n",
        "\\right)^{\\tfrac{1}{p}},\n",
        "\\quad p \\ge 1\n",
        "$$\n",
        "\n",
        "donde:\n",
        "- $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ son dos puntos,\n",
        "- $p$ define cómo se penalizan las diferencias entre componentes.\n",
        "\n",
        "Casos importantes:\n",
        "- $p = 1$ → **distancia Manhattan (L1)**\n",
        "- $p = 2$ → **distancia Euclidiana (L2)**\n",
        "\n",
        "Minkowski unifica distintas nociones de distancia en una sola fórmula; cambiar $p$ cambia la geometría del espacio."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1ce129e",
      "metadata": {
        "id": "b1ce129e"
      },
      "source": [
        "## 3. Agregando regularización L2 a la función del error\n",
        "La **regularización L2 (Ridge)** añade una penalización sobre la magnitud de los pesos:\n",
        "\n",
        "$$\n",
        "J_{\\text{Ridge}}(\\mathbf{w}) =\n",
        "\\underbrace{\\frac{1}{n}\\sum_{i=1}^{n}\\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2}_{\\text{error de ajuste}}\n",
        "+\n",
        "\\underbrace{\\lambda \\left(w_1^2 + w_2^2\\right)}_{\\text{penalización L2}}\n",
        "$$\n",
        "\n",
        "donde:\n",
        "- $\\lambda \\ge 0$ controla la intensidad de la regularización.\n",
        "- Pesos grandes implican mayor penalización.\n",
        "\n",
        "\n",
        "La **distancia de Minkowski de grado 2** es la **distancia euclidiana**:\n",
        "$$\n",
        "d_2(\\mathbf{x}, \\mathbf{y})\n",
        "=\n",
        "\\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
        "$$\n",
        "\n",
        "Si fijamos $\\mathbf{y} = \\mathbf{0}$, obtenemos la **norma euclidiana**:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{x}\\|_2 = d_2(\\mathbf{x}, \\mathbf{0})\n",
        "$$\n",
        "\n",
        "\n",
        "La regularización Ridge penaliza el **cuadrado de la norma euclidiana** de los pesos:\n",
        "\n",
        "$$\n",
        "\\lambda \\|\\mathbf{w}\\|_2^2\n",
        "=\n",
        "\\lambda \\sum_{j} w_j^2\n",
        "$$\n",
        "\n",
        "Esto significa que Ridge:\n",
        "\n",
        "- mide **qué tan lejos está el vector de pesos del origen** usando Minkowski de grado 2,\n",
        "- penaliza **fuertemente los pesos lejanos al origen**,\n",
        "- favorece soluciones con **pesos pequeños**.\n",
        "\n",
        "\n",
        "Interpretación geométrica\n",
        "\n",
        "- La distancia Minkowski de grado 2 define **esferas** (bolas euclidianas).\n",
        "- Ridge restringe la solución a estar **cerca del origen dentro de una esfera L2** porque una norma mide el tamaño de un solo vector. Y ese tamaño se define como su distancia al origen.\n",
        "- Por eso Ridge **encoge** los coeficientes, pero no los lleva exactamente a cero.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61f901b2",
      "metadata": {
        "id": "61f901b2"
      },
      "source": [
        "## 4. La metáfora geométrica: la “cresta” (*ridge*)\n",
        "\n",
        "*Ridge* significa *una cresta larga y elevada sobre una superficie*.\n",
        "\n",
        "En mínimos cuadrados ordinarios (OLS), la superficie del error suele tener la forma de un **valle alargado y plano**.\n",
        "\n",
        "La regularización L2 modifica la función de costo:\n",
        "\n",
        "$$\n",
        "J(\\mathbf{w})\n",
        "=\n",
        "\\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2\n",
        "+\n",
        "\\lambda \\|\\mathbf{w}\\|_2^2\n",
        "$$\n",
        "\n",
        "Geométricamente, el término $\\lambda \\|\\mathbf{w}\\|_2^2$ **eleva** el fondo del valle y el efecto es como **levantar una cresta** sobre el valle original.\n",
        "- El **subíndice 2** en $\\|\\mathbf{w}\\|_2$ indica que se utiliza la **norma $\\ell_2$** (norma euclidiana).\n",
        "- El **superíndice 2** indica que dicha norma se **eleva al cuadrado**.\n",
        "\n",
        "En forma explícita:\n",
        "\n",
        "$$\n",
        "\\lambda \\|\\mathbf{w}\\|_2^2\n",
        "=\n",
        "\\lambda \\sum_j w_j^2\n",
        "$$\n",
        "\n",
        "Se usa el cuadrado para eliminar la raíz, simplificar el gradiente y mantener una penalización suave y convexa.\n",
        "\n",
        "La regularización no cambia la forma global del valle, pero **añade una elevación** que evita soluciones degeneradas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c40bac1",
      "metadata": {
        "id": "5c40bac1"
      },
      "source": [
        "# Regularización L1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "La **regularización L1** introduce una penalización basada en la **norma L1**, que es un caso particular de la **distancia de Minkowski**.\n",
        "\n",
        "### 1. Distancia de Minkowski\n",
        "\n",
        "La distancia de Minkowski entre dos vectores $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d$ está definida como:\n",
        "\n",
        "$$\n",
        "d_p(\\mathbf{x}, \\mathbf{y}) =\n",
        "\\left( \\sum_{j=1}^{d} |x_j - y_j|^p \\right)^{1/p}, \\quad p \\ge 1\n",
        "$$\n",
        "\n",
        "Casos particulares importantes:\n",
        "- $p = 2$: distancia Euclidiana (norma L2)\n",
        "- $p = 1$: distancia Manhattan (norma L1)\n",
        "\n",
        "Para regularización, se considera la distancia al **origen**, es decir, una norma.\n",
        "\n",
        "\n",
        "\n",
        "### 2. Norma L1 como distancia de Minkowski\n",
        "\n",
        "La **norma L1** de un vector de parámetros $\\mathbf{w}$ es:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{w}\\|_1 = \\sum_{j=1}^{d} |w_j|\n",
        "$$\n",
        "\n",
        "Esto equivale a la distancia de Minkowski con $p = 1$ entre $\\mathbf{w}$ y el vector cero.\n",
        "\n",
        "\n",
        "\n",
        "### 3. Regularización L1 en regresión\n",
        "\n",
        "En un problema de regresión lineal, la función de costo regularizada con L1 es:\n",
        "\n",
        "$$\n",
        "J(\\mathbf{w}) =\n",
        "\\frac{1}{2n}\\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2\n",
        "\\;+\\;\n",
        "\\lambda \\|\\mathbf{w}\\|_1\n",
        "$$\n",
        "\n",
        "donde:\n",
        "- $\\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2$ mide el error de ajuste,\n",
        "- $\\|\\mathbf{w}\\|_1$ mide la distancia Manhattan de $\\mathbf{w}$ al origen,\n",
        "- $\\lambda > 0$ controla la intensidad de la regularización.\n",
        "\n",
        "\n",
        "\n",
        "### 4. Propiedades clave de la regularización L1\n",
        "\n",
        "**(a) Esparsidad**\n",
        "- Produce coeficientes exactamente cero.\n",
        "- Realiza selección de variables de forma implícita.\n",
        "\n",
        "**(b) Relación con Minkowski**\n",
        "- Cambiar $p$ en Minkowski cambia la geometría de la restricción:\n",
        "  - $p=1$: esquinas → esparsidad.\n",
        "  - $p=2$: superficie suave → coeficientes pequeños pero no nulos.\n",
        "\n",
        "\n",
        "\n",
        "### 5. Comparación conceptual L1 vs L2\n",
        "\n",
        "| Regularización | Norma (Minkowski) | Geometría | Efecto |\n",
        "|---------------|-------------------|-----------|--------|\n",
        "| L1 (Lasso) | $p=1$ | Rombo | Coeficientes exactos en cero |\n",
        "| L2 (Ridge) | $p=2$ | Esfera | Coeficientes pequeños |\n",
        "| Elastic Net | $p=1$ + $p=2$ | Mixta | Esparsidad + estabilidad |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QjV47gZ53_eN"
      },
      "id": "QjV47gZ53_eN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elastic Net\n",
        "\n",
        "La **regularización Elastic Net** combina las penalizaciones **L1** y **L2**, integrando dos geometrías inducidas por la distancia de Minkowski. Esto permite equilibrar **esparsidad**, **estabilidad numérica** y **manejo de variables correlacionadas**.\n",
        "\n",
        "\n",
        "### 1. Recordatorio: Minkowski y normas\n",
        "\n",
        "La distancia de Minkowski para $p \\ge 1$ es:\n",
        "\n",
        "$$\n",
        "d_p(\\mathbf{x}, \\mathbf{y}) =\n",
        "\\left( \\sum_{j=1}^{d} |x_j - y_j|^p \\right)^{1/p}\n",
        "$$\n",
        "\n",
        "Al medir la distancia al origen obtenemos normas:\n",
        "- $p = 1 \\Rightarrow \\|\\cdot\\|_1$ (Manhattan)\n",
        "- $p = 2 \\Rightarrow \\|\\cdot\\|_2$ (Euclidiana)\n",
        "\n",
        "Elastic Net **no corresponde a un único valor de $p$**, sino a una **combinación de dos normas de Minkowski**.\n",
        "\n",
        "\n",
        "### 2. Función de costo de Elastic Net\n",
        "\n",
        "En regresión lineal, Elastic Net se define como:\n",
        "\n",
        "$$\n",
        "J(\\mathbf{w}) =\n",
        "\\frac{1}{2n}\\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2\n",
        "\\;+\\;\n",
        "\\lambda \\Big(\n",
        "\\alpha \\|\\mathbf{w}\\|_1\n",
        "+\n",
        "(1-\\alpha)\\|\\mathbf{w}\\|_2^2\n",
        "\\Big)\n",
        "$$\n",
        "\n",
        "donde:\n",
        "- $\\lambda > 0$ controla la regularización total,\n",
        "- $\\alpha \\in [0,1]$ controla el balance L1–L2,\n",
        "- $\\alpha = 1$ → Lasso,\n",
        "- $\\alpha = 0$ → Ridge.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Interpretación geométrica (Minkowski híbrida)\n",
        "\n",
        "Elastic Net impone la restricción:\n",
        "\n",
        "$$\n",
        "\\alpha \\|\\mathbf{w}\\|_1 + (1-\\alpha)\\|\\mathbf{w}\\|_2^2 \\le c\n",
        "$$\n",
        "\n",
        "\n",
        "### 4. Por qué Elastic Net funciona mejor con variables correlacionadas\n",
        "\n",
        "- **L1 puro (Lasso):** tiende a seleccionar **una sola** variable dentro de un grupo altamente correlacionado.\n",
        "- **L2 (Ridge):** distribuye el peso entre todas, pero no elimina ninguna.\n",
        "- **Elastic Net:** selecciona **grupos de variables correlacionadas**, asignándoles coeficientes similares.\n",
        "\n",
        "\n",
        "### 5. Propiedades teóricas\n",
        "\n",
        "\n",
        "**(a) Esparsidad controlada**\n",
        "- Producida por el término L1.\n",
        "- Ajustable mediante $\\alpha$.\n",
        "\n",
        "**(b) Estabilidad numérica**\n",
        "- El término L2 evita soluciones inestables cuando:\n",
        "  - $p \\gg n$\n",
        "  - $\\mathbf{X}^\\top \\mathbf{X}$ es mal condicionada o singular.\n",
        "\n",
        "\n",
        "### 6. Elastic Net como regularización Minkowski compuesta\n",
        "\n",
        "Desde el punto de vista geométrico:\n",
        "\n",
        "- L1 mide complejidad usando la **distancia Manhattan**,\n",
        "- L2 mide complejidad usando la **distancia Euclidiana**,\n",
        "- Elastic Net **combina ambas nociones de distancia** para definir qué significa un modelo “simple”.\n",
        "\n",
        "\n",
        "\n",
        "### 7. Comparación resumida\n",
        "\n",
        "| Método | Norma (Minkowski) | Geometría | Comportamiento |\n",
        "|------|-------------------|-----------|----------------|\n",
        "| Lasso | $p=1$ | Rombo | Esparsidad fuerte |\n",
        "| Ridge | $p=2$ | Esfera | Estabilidad |\n",
        "| Elastic Net | $p=1$ + $p=2$ | Híbrida | Esparsidad + agrupamiento |\n",
        "\n",
        "\n",
        "\n",
        "> **Elastic Net redefine la noción de complejidad del modelo como una combinación de distancias de Minkowski, logrando soluciones esparsas pero geométricamente más estables y realistas en presencia de correlación.**\n",
        "\n",
        "Elastic Net suele superar a Lasso y Ridge en escenarios de alta dimensionalidad."
      ],
      "metadata": {
        "id": "SZumfBLz4Tuq"
      },
      "id": "SZumfBLz4Tuq"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mlstudy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}